{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emilevillette/Emilevillette/blob/main/SIMD_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINFO2241 : Practical Session 8\n",
        "\n",
        "# Exercice 1 : SIMD"
      ],
      "metadata": {
        "id": "ih46-48nUPEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 : Turning a regular program into AVX\n",
        "\n",
        "This exercice consist in understanding a rather basic C program, and adapt it so that it can run in AVX, AVX2 and AVX512. We'll then look at how well each implementation performs"
      ],
      "metadata": {
        "id": "hKoWP5R0djLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preliminary steps\n",
        "\n",
        "#### Checking CPU support\n",
        "\n",
        "To use AVX, AVX2 and AVX512, we need the support from the CPU. Check the flags of /proc/cpuinfo"
      ],
      "metadata": {
        "id": "nJ4nnVKoVGbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget the scroll bar to see the line to the end. You should see the *avx*, *avx2* and different variant of *avx512* in the flag section. This indicates that the process has hardware support for each version of AVX. You can check on your own computer if you wan (hint : On your local machine, you'll probably have support for AVX and AVX2, but likely not for AVX512)."
      ],
      "metadata": {
        "id": "T_TYYgVfVSz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep avx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dri1Mj2pUAjT",
        "outputId": "7826425c-ecdf-4242-8038-1bead5874e4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create basic files\n",
        "\n",
        "This is the skeleton you'll need later, just execute these cells to create the required file. You don't have to edit it.\n",
        "\n",
        "But look at the `aligned_alloc` functions, what do they do ? Why 64 ?"
      ],
      "metadata": {
        "id": "8NryUKxPV68V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avx.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "unsigned long long rdtscl(void)\n",
        "{\n",
        "    unsigned int lo, hi;\n",
        "    __asm__ __volatile__ (\"rdtsc\" : \"=a\"(lo), \"=d\"(hi));\n",
        "    return ( (unsigned long long)lo)|( ((unsigned long long)hi)<<32 );\n",
        "}\n",
        "\n",
        "long N = 65536;\n",
        "\n",
        "void VecAdd(float* A, float* B, float* C, long N);\n",
        "\n",
        "// Host code\n",
        "int main()\n",
        "{\n",
        "\n",
        "    size_t size = N * sizeof(float);\n",
        "    // Allocate input vectors h_A and h_B in host memory\n",
        "    float* A = (float*)aligned_alloc(64, size);\n",
        "    float* B = (float*)aligned_alloc(64, size);\n",
        "    float* C = (float*)aligned_alloc(64, size);\n",
        "\n",
        "    // Initialize input vectors\n",
        "    for (int i = 0; i < N; i ++) {\n",
        "        A[i] = (float)i;\n",
        "        B[i] = (float)i;\n",
        "        //C[i] = 0; will be overwritten, don't care\n",
        "    }\n",
        "\n",
        "    printf(\"Launching computation...\\n\");\n",
        "    unsigned long long start = rdtscl();\n",
        "    VecAdd(A, B, C, N);\n",
        "\n",
        "    printf(\"Finished in %llu cycles !\\n\", rdtscl() - start);\n",
        "\n",
        "    printf(\"First floats of C : %f %f %f ...\\n\", C[0], C[1] , C[2]);\n",
        "\n",
        "    // Free host memory\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    printf(\"Exiting...\");\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pnBUu-0JDLg",
        "outputId": "c54e35e2-f895-4618-cb4d-12f7cc1f7616"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing avx.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing you own implementation\n",
        "\n",
        "Look a this naive implementation and write an equivalent in AVX, AVX2 and AVX512\n",
        "\n",
        "#### Naive implementation"
      ],
      "metadata": {
        "id": "eKwJm1dJYOyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile naive.c\n",
        "\n",
        "// Naive implementation, you don't have to edit it\n",
        "void VecAdd(float* A, float* B, float* C, long N)\n",
        "{\n",
        "    for (int i = 0; i < N; i++)\n",
        "        C[i] = A[i] + B[i];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0CQLIx4Ygy-",
        "outputId": "4b429092-563c-4630-e29f-fa589cae884f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing naive.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that it works by compiling and running it"
      ],
      "metadata": {
        "id": "-hkAcHrcZMBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c naive.c -o naive\n",
        "!./naive"
      ],
      "metadata": {
        "id": "5GdLvKLiJHkE",
        "outputId": "a9b24f77-6335-43cc-8349-2cf5b253ee88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n",
            "Finished in 950400 cycles !\n",
            "First floats of C : 0.000000 2.000000 4.000000 ...\n",
            "Exiting..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AVX128 implementation"
      ],
      "metadata": {
        "id": "U0Usz4Ccbayi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avx128.c\n",
        "#include <immintrin.h>\n",
        "\n",
        "void VecAdd(float* A, float* B, float* C, long N)\n",
        "{\n",
        "  // Your code here\n",
        "  for(int i = 0; i<N; i+=4) {\n",
        "    __m128 a = _mm_load_ps(A+i);\n",
        "    __m128 b = _mm_load_ps(B+i);\n",
        "    __m128 result = _mm_add_ps(a, b);\n",
        "    _mm_store_ps(C+i, result);\n",
        "  }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d36276d-71bf-4282-feb9-db582ea04072",
        "id": "qyPEwHtqblK0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avx128.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c avx128.c -o avx\n",
        "!./avx"
      ],
      "metadata": {
        "id": "hcZmIdddbqQb",
        "outputId": "a21a3c70-de79-454a-fcc7-a049ae6e90f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n",
            "Finished in 617058 cycles !\n",
            "First floats of C : 0.000000 2.000000 4.000000 ...\n",
            "Exiting..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AVX256 implementation"
      ],
      "metadata": {
        "id": "Dtq1qA-Yb_kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avx256.c\n",
        "#include <immintrin.h>\n",
        "\n",
        "void VecAdd(float* A, float* B, float* C, long N)\n",
        "{\n",
        "  // Your code here\n",
        "  for(int i = 0; i<N; i+=8) {\n",
        "    __m256 a = _mm256_load_ps(A+i);\n",
        "    __m256 b = _mm256_load_ps(B+i);\n",
        "    __m256 result = _mm256_add_ps(a, b);\n",
        "    _mm256_store_ps(C+i, result);\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea7e040-44b9-4625-d4a4-ca4de3f567eb",
        "id": "NJsW8rgJb_kk"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avx256.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c avx256.c -o avx2\n",
        "!./avx2"
      ],
      "metadata": {
        "id": "C8Wx_60hb_km",
        "outputId": "6a8a29e7-9771-4c0b-84a7-ae54def489e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n",
            "Finished in 387120 cycles !\n",
            "First floats of C : 0.000000 2.000000 4.000000 ...\n",
            "Exiting..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AVX512 implementation"
      ],
      "metadata": {
        "id": "uj9DrUuBcLMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sadly, AVX512 isn't always available on Google Collab. You need to setup your colab environment to run with a GPU (We won't use the GPU right now, but the GPU machine happens to be AVX512 compatible)."
      ],
      "metadata": {
        "id": "5FTak4sblJ8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile avx512.c\n",
        "#include <immintrin.h>\n",
        "\n",
        "void VecAdd(float *A, float *B, float *C, long N) {\n",
        "  // Your code here\n",
        "  for(int i = 0; i<N; i+=16) {\n",
        "    __m512 a = _mm512_load_ps(A+i);\n",
        "    __m512 b = _mm512_load_ps(B+i);\n",
        "    __m512 result = _mm512_add_ps(a, b);\n",
        "    _mm512_store_ps(C+i, result);\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876743ef-2b96-4176-db9f-4f177b5e54ce",
        "id": "lZM3pLRecLMo"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avx512.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c avx512.c -mavx512bw -o avx512\n",
        "!./avx512"
      ],
      "metadata": {
        "id": "TVQhkWcxcLMp",
        "outputId": "8fe39651-76cf-4a8e-f0d1-3a24bb8bc6eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n",
            "Finished in 397960 cycles !\n",
            "First floats of C : 0.000000 2.000000 4.000000 ...\n",
            "Exiting..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performances\n",
        "\n",
        "Can you see a difference in performances ? Maybe you'll have to increase the value of N to have significant result. (If so, don't forget to recompile everything)"
      ],
      "metadata": {
        "id": "MT2ACm19cuPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./naive\n",
        "!./avx\n",
        "!./avx2\n",
        "!./avx512"
      ],
      "metadata": {
        "id": "ErueSd8UcxYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 : Branching and masks"
      ],
      "metadata": {
        "id": "F9Id05tTdw4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the code below, it uses branching to perform multiplication on odd indexes (Note: odd means 'impair' in english). How can we perform this with AVX ?"
      ],
      "metadata": {
        "id": "8joY77UMd3RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conditional.c\n",
        "// Code. Well this is still not vectorized\n",
        "void VecAdd(float* A, float* B, float* C, long N)\n",
        "{\n",
        "    for (int i = 0; i < N; i++)\n",
        "        if (i % 2 == 0)\n",
        "            C[i] = A[i] + B[i];\n",
        "        else\n",
        "            C[i] = A[i] * B[i];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtX882GfeV6Q",
        "outputId": "a285a9f6-9db6-4257-8198-17b8f604de6a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conditional.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c conditional.c -o avx_conditional\n",
        "!./avx_conditional"
      ],
      "metadata": {
        "id": "AQ2jIYtkelnh",
        "outputId": "fa577e41-0224-49cc-903b-0b2c4519f46b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n",
            "Finished in 1129280 cycles !\n",
            "First floats of C : 0.000000 1.000000 4.000000 ...\n",
            "Exiting..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use masks and blenders to write an AVX version of this program. You're free to use the AVX version you want (AVX, AVX2 or AVX512)."
      ],
      "metadata": {
        "id": "PMiFpB2zeuDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mask.c\n",
        "// Code. Well this is still not vectorized\n",
        "#include <immintrin.h>\n",
        "\n",
        "void VecAdd(float* A, float* B, float* C, long N)\n",
        "{\n",
        "  // Your code here\n",
        "  for (int i = 0; i < N; i+=16) {\n",
        "    __m512 a = _mm512_load_ps(A+i);\n",
        "    __m512 b = _mm512_load_ps(B+i);\n",
        "    int array[16];\n",
        "    if (i%2 == 0) {\n",
        "      int array[16] = {0, 1, 0, 1 ,0, 1 ,0, 1, 0, 1, 0, 1 ,0, 1 ,0, 1};\n",
        "    } else {\n",
        "      int array[16] = {1 ,0,1 ,0,1 ,0,1 ,0, 1 ,0,1 ,0,1 ,0,1 ,0};\n",
        "    }\n",
        "    __m512i arr = _mm512_load_epi32(array);\n",
        "    __mmask32 mask = _mm512_cmpeq_epi32_mask(arr, _mm512_set_epi32(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0));\n",
        "\n",
        "    __m512 result = _mm512_mask_add_ps(a, mask, a, b);\n",
        "    __m512 other_result = _mm512_maskz_mul_ps(mask, a, b);\n",
        "\n",
        "    __m512 real_result = _mm512_mask_blend_ps(mask, result, other_result);\n",
        "\n",
        "    _mm512_store_ps(C+i, real_result);\n",
        "  }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I0hw8w9e2U8",
        "outputId": "e858eb12-9027-450c-c9ef-734429cceeb4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mask.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -march=native avx.c mask.c -o avx_mask\n",
        "!./avx_mask"
      ],
      "metadata": {
        "id": "qDOzkFrpfSrw",
        "outputId": "5dc2007a-f04e-4bc7-8e6c-e6d126c2d2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching computation...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performances\n",
        "\n",
        "What can you say about each implementation performances ?"
      ],
      "metadata": {
        "id": "i8raWaKnfdZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./avx_conditional\n",
        "!./avx_mask"
      ],
      "metadata": {
        "id": "DmaPxF4DfnqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}